{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45db9291-b147-4c46-a408-322a50795790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import os\n",
    "\n",
    "def download_and_extract_dataset(url, extract_to='./dataset'):\n",
    "    print(\"Downloading dataset...\")\n",
    "    response = requests.get(url)\n",
    "    print(\"Download complete. Extracting...\")\n",
    "    z = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "    z.extractall(extract_to)\n",
    "    print(f\"Dataset extracted to {extract_to}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_url = \"https://dicom5c.blob.core.windows.net/public/Data.zip\"\n",
    "    download_and_extract_dataset(dataset_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f9fe8d-c7c3-4212-ab0e-d48ea3c731ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import albumentations as A\n",
    "\n",
    "class BrainMRIDataLoader:\n",
    "    def __init__(self, data_dir, img_size=(256, 256), batch_size=32):\n",
    "        self.data_dir = data_dir\n",
    "        self.img_size = img_size\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def load_data(self):\n",
    "        images = []\n",
    "        masks = []\n",
    "        for filename in os.listdir(self.data_dir):\n",
    "            if filename.endswith(('_1.tif', '_2.tif', '_3.tif', '_4.tif', '_5.tif')):\n",
    "                img_path = os.path.join(self.data_dir, filename)\n",
    "                mask_path = os.path.join(self.data_dir, filename.replace('.tif', '_mask.tif'))\n",
    "                \n",
    "                if os.path.exists(mask_path):\n",
    "                    img = self._load_img(img_path)\n",
    "                    mask = self._load_img(mask_path)\n",
    "                    \n",
    "                    images.append(img)\n",
    "                    masks.append(mask)\n",
    "        \n",
    "        return np.array(images), np.array(masks)\n",
    "    \n",
    "    def _load_img(self, path):\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_tiff(img)\n",
    "        img = tf.image.resize(img, self.img_size)\n",
    "        img = tf.cast(img, tf.float32) / 255.0\n",
    "        return img.numpy()\n",
    "    \n",
    "    def preprocess(self, image, mask):\n",
    "        augmentor = A.Compose([\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=45, p=0.5),\n",
    "            A.OneOf([\n",
    "                A.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03, p=0.5),\n",
    "                A.GridDistortion(p=0.5),\n",
    "                A.OpticalDistortion(distort_limit=1, shift_limit=0.5, p=0.5),\n",
    "            ], p=0.3),\n",
    "            A.CLAHE(clip_limit=2.0, p=0.8),\n",
    "            A.RandomBrightnessContrast(p=0.8),    \n",
    "            A.RandomGamma(p=0.8),\n",
    "        ])\n",
    "        \n",
    "        augmented = augmentor(image=image, mask=mask)\n",
    "        return augmented['image'], augmented['mask']\n",
    "\n",
    "    def create_dataset(self, X, y):\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "        dataset = dataset.map(lambda x, y: tf.numpy_function(self.preprocess, [x, y], [tf.float32, tf.float32]),\n",
    "                              num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        dataset = dataset.batch(self.batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bdeae7-3845-4010-bd61-bf22a7cb7a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "class AttentionGate(layers.Layer):\n",
    "    def __init__(self, filters):\n",
    "        super(AttentionGate, self).__init__()\n",
    "        self.W_g = layers.Conv2D(filters, 1, padding='same')\n",
    "        self.W_x = layers.Conv2D(filters, 1, padding='same')\n",
    "        self.psi = layers.Conv2D(1, 1, padding='same')\n",
    "        \n",
    "    def call(self, g, x):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = tf.keras.activations.relu(g1 + x1)\n",
    "        psi = self.psi(psi)\n",
    "        return tf.keras.activations.sigmoid(psi) * x\n",
    "\n",
    "def attention_unet(input_size=(256, 256, 1), num_classes=1):\n",
    "    inputs = layers.Input(input_size)\n",
    "    \n",
    "    # Encoder\n",
    "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
    "    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
    "    drop4 = layers.Dropout(0.5)(conv4)\n",
    "    pool4 = layers.MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "    \n",
    "    # Bridge\n",
    "    conv5 = layers.Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n",
    "    conv5 = layers.Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n",
    "    drop5 = layers.Dropout(0.5)(conv5)\n",
    "    \n",
    "    # Decoder\n",
    "    up6 = layers.UpSampling2D(size=(2, 2))(drop5)\n",
    "    up6 = layers.Conv2D(512, 2, activation='relu', padding='same')(up6)\n",
    "    attn6 = AttentionGate(512)(g=up6, x=drop4)\n",
    "    merge6 = layers.concatenate([up6, attn6])\n",
    "    conv6 = layers.Conv2D(512, 3, activation='relu', padding='same')(merge6)\n",
    "    conv6 = layers.Conv2D(512, 3, activation='relu', padding='same')(conv6)\n",
    "    \n",
    "    up7 = layers.UpSampling2D(size=(2, 2))(conv6)\n",
    "    up7 = layers.Conv2D(256, 2, activation='relu', padding='same')(up7)\n",
    "    attn7 = AttentionGate(256)(g=up7, x=conv3)\n",
    "    merge7 = layers.concatenate([up7, attn7])\n",
    "    conv7 = layers.Conv2D(256, 3, activation='relu', padding='same')(merge7)\n",
    "    conv7 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv7)\n",
    "    \n",
    "    up8 = layers.UpSampling2D(size=(2, 2))(conv7)\n",
    "    up8 = layers.Conv2D(128, 2, activation='relu', padding='same')(up8)\n",
    "    attn8 = AttentionGate(128)(g=up8, x=conv2)\n",
    "    merge8 = layers.concatenate([up8, attn8])\n",
    "    conv8 = layers.Conv2D(128, 3, activation='relu', padding='same')(merge8)\n",
    "    conv8 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv8)\n",
    "    \n",
    "    up9 = layers.UpSampling2D(size=(2, 2))(conv8)\n",
    "    up9 = layers.Conv2D(64, 2, activation='relu', padding='same')(up9)\n",
    "    attn9 = AttentionGate(64)(g=up9, x=conv1)\n",
    "    merge9 = layers.concatenate([up9, attn9])\n",
    "    conv9 = layers.Conv2D(64, 3, activation='relu', padding='same')(merge9)\n",
    "    conv9 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv9)\n",
    "    \n",
    "    outputs = layers.Conv2D(num_classes, 1, activation='sigmoid')(conv9)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423fcdaf-3312-43d2-9a97-e4d977af3564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from data_loader import BrainMRIDataLoader\n",
    "from models import attention_unet\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_model(model, train_dataset, val_dataset, epochs=100):\n",
    "    callbacks = [\n",
    "        ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss'),\n",
    "        ReduceLROnPlateau(factor=0.1, patience=5, min_lr=1e-6, verbose=1),\n",
    "        EarlyStopping(patience=10, verbose=1)\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    return history\n",
    "\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(121)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_loader = BrainMRIDataLoader('./dataset')\n",
    "    X, y = data_loader.load_data()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    train_dataset = data_loader.create_dataset(X_train, y_train)\n",
    "    val_dataset = data_loader.create_dataset(X_test, y_test)\n",
    "\n",
    "    model = attention_unet()\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = train_model(model, train_dataset, val_dataset)\n",
    "    plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ace94bb-046a-4059-8c31-4ad015cf328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import tensorflow as tf\n",
    "from data_loader import BrainMRIDataLoader\n",
    "from models import attention_unet\n",
    "\n",
    "def dice_coefficient(y_true, y_pred, smooth=1):\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = np.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)\n",
    "\n",
    "def evaluate_model(model, test_dataset):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for images, masks in test_dataset:\n",
    "        predictions = model.predict(images)\n",
    "        y_true.extend(masks.numpy().flatten())\n",
    "        y_pred.extend(predictions.flatten())\n",
    "    \n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "    \n",
    "    dice = dice_coefficient(y_true, y_pred_binary)\n",
    "    precision = precision_score(y_true, y_pred_binary)\n",
    "    recall = recall_score(y_true, y_pred_binary)\n",
    "    f1 = f1_score(y_true, y_pred_binary)\n",
    "    \n",
    "    print(f\"Dice Coefficient: {dice:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred_binary)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_loader = BrainMRIDataLoader('./dataset')\n",
    "    X, y = data_loader.load_data()\n",
    "    _, X_test, _, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    test_dataset = data_loader.create_dataset(X_test, y_test)\n",
    "\n",
    "    model = tf.keras.models.load_model('best_model.h5', custom_objects={'AttentionGate': AttentionGate})\n",
    "    evaluate_model(model, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29ee947-b35e-4b24-8406-770174ee24b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, File, UploadFile, HTTPException\n",
    "from fastapi.responses import JSONResponse\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import io\n",
    "from PIL import Image\n",
    "import base64\n",
    "from models import AttentionGate\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "model = tf.keras.models.load_model('best_model.h5', custom_objects={'AttentionGate': AttentionGate})\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.resize(image, (256, 256))\n",
    "    image = image.astype(np.float32) / 255.0\n",
    "    return np.expand_dims(image, axis=[0, -1])\n",
    "\n",
    "@app.post(\"/predict/\")\n",
    "async def predict(file: UploadFile = File(...)):\n",
    "    if file.content_type.split('/')[0] != 'image':\n",
    "        raise HTTPException(status_code=400, detail=\"File is not an image.\")\n",
    "    \n",
    "    contents = await file.read()\n",
    "    nparr = np.frombuffer(contents, np.uint8)\n",
    "    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    preprocessed_img = preprocess_image(img)\n",
    "    prediction = model.predict(preprocessed_img)\n",
    "    \n",
    "    binary_mask = (prediction > 0.5).astype(np.uint8)\n",
    "    binary_mask = np.squeeze(binary_mask) * 255\n",
    "    \n",
    "    # Create a color overlay\n",
    "    color_mask = cv2.applyColorMap(binary_mask,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
